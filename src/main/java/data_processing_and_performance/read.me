When palatalization

-   If in doubt, measure. Turning a sequential stream into a parallel one is trivial but not always the right
    thing to do. As we already demonstrated in this section, a parallel stream isn’t always faster than the
    corresponding sequential version. Moreover, parallel streams can sometimes work in a
    counterintuitive way, so the first and most important suggestion when choosing between sequential
    and parallel streams is to always check their performance with an appropriate benchmark.

-   Watch out for boxing. Automatic boxing and unboxing operations can dramatically hurt performance.
    Java 8 includes primitive streams ( IntStream , LongStream , and DoubleStream ) to avoid such
    operations, so use them when possible.

-   Some operations naturally perform worse on a parallel stream than on a sequential stream. In
    particular, operations such as limit and findFirst that rely on the order of the elements are expensive
    in a parallel stream. For example, findAny will perform better than findFirst because it isn’t
    constrained to operate in the encounter order. You can always turn an ordered stream into an
    unordered stream by invoking the method unordered on it. So, for instance, if you need N elements
    of your stream and you’re not necessarily interested in the first N ones, calling limit on an unordered
    parallel stream may execute more efficiently than on a stream with an encounter order (for example,
    when the source is a List ).

-   Consider the total computational cost of the pipeline of operations performed by the stream. With N
    being the number of elements to be processed and Q the approximate cost of processing one of these
    elements through the stream pipeline, the product of N*Q gives a rough qualitative estimation of this
    cost. A higher value for Q implies a better chance of good performance when using a parallel stream.

-   For a small amount of data, choosing a parallel stream is almost never a winning decision. The
    advantages of processing in parallel only a few elements aren’t enough to compensate for the
    additional cost introduced by the parallelization process.

-   Take into account how well the data structure underlying the stream decomposes. For instance, an
    ArrayList can be split much more efficiently than a LinkedList , because the first can be evenly
    divided without traversing it, as it’s necessary to do with the second. Also, the primitive streams
    created with the range factory method can be decomposed quickly. Finally, as you’ll learn in section
    7.3, you can get full control of this decomposition process by implementing your own Spliterator .

-   The characteristics of a stream, and how the intermediate operations through the pipeline modify
    them, can change the performance of the decomposition process. For example, a SIZED stream can
    be divided into two equal parts, and then each part can be processed in parallel more effectively, but a
    filter operation can throw away an unpredictable number of elements, making the size of the stream
    itself unknown.

-   Consider whether a terminal operation has a cheap or expensive merge step (for example, the
    combiner method in a Collector ). If this is expensive, then the cost caused by the combination of the
    partial results generated by each substream can outweigh the performance benefits of a parallel
    stream.

Table 7.1 gives a summary of the parallel-friendliness of certain stream sources in terms of their
decomposability.
Table 7.1. Stream sources and decomposability
Source              Decomposability
    ArrayList       Excellent
    LinkedList      Poor
    IntStream.range Excellent
    Stream.iterate  Poor
    HashSet         Good
    TreeSet         Good

// Best practices for using the fork/join framework

-   Invoking the join method on a task blocks the caller until the result produced by that task is ready.
    For this reason, it’s necessary to call it after the computation of both subtasks has been started.
    Otherwise, you’ll end up with a slower and more complex version of your original sequential algorithm
    because every subtask will have to wait for the other one to complete before starting.

-   The invoke method of a ForkJoinPool shouldn’t be used from within a RecursiveTask . Instead,
    you should always call the methods compute or fork directly; only sequential code should use
    invoke to begin parallel computation.

-   Calling the fork method on a subtask is the way to schedule it on the ForkJoinPool . It might seem
    natural to invoke it on both the left and right subtasks, but this is less efficient than just directly
    calling compute on one of them. Doing this allows you to reuse the same thread for one of the two
    subtasks and avoid the overhead caused by the unnecessary allocation of a further task on the pool.

-   Debugging a parallel computation using the fork/join framework can be tricky. In particular, it’s
    ordinarily quite common to browse a stack trace in your favorite IDE to discover the cause of a
    problem, but this can’t work with a fork-join computation because the call to compute occurs in a
    different thread than the conceptual caller, which is the code that called fork .

-   As you’ve discovered with parallel streams, you should never take for granted that a computation
    using the fork/join framework on a multicore processor is faster than the sequential counterpart. We
    already said that a task should be decomposable into several independent subtasks in order to be
    parallelizable with a relevant performance gain. All of these subtasks should take longer to execute
    than forking a new task; one idiom is to put I/O into one subtask and computation into another,
    thereby overlapping computation with I/O. Moreover, you should consider other things when
    comparing the performance of the sequential and parallel versions of the same algorithm. Like any
    other Java code, the fork/join framework needs to be “warmed up,” or executed, a few times before
    being optimized by the JIT compiler. This is why it’s always important to run the program multiple
    times before to measure its performance, as we did in our harness. Also be aware that optimizations
    built into the compiler could unfairly give an advantage to the sequential version (for example, by
    performing dead code analysis—removing a computation that’s never used).

// Spliterator

-   The tryAdvance method feeds the Consumer with the Character in the String at the current index
    position and increments this position. The Consumer passed as argument is an internal Java class
    forwarding the consumed Character to the set of functions that have to be applied to it while
    traversing the stream, which in this case is only a reducing function, namely, the accumulate method
    of the WordCounter class. The tryAdvance method returns true if the new cursor position is less
    than the total String length and there are further Character s to be iterated.

-   The trySplit method is the most important one in a Spliterator because it’s the one defining the
    logic used to split the data structure to be iterated. As you did in the compute method of the
    RecursiveTask implemented in listing 7.1 (on how to use the fork/join framework), the first thing
    you have to do here is set a limit under which you don’t want to perform further splits. Here, you use a
    very low limit of 10 Character s only to make sure that your program will perform some splits with
    the relatively short String you’re parsing, but in real-world applications you’ll have to use a higher
    limit, as you did in the fork/join example, to avoid creating too many tasks. If the number of
    remaining Character s to be traversed is under this limit, you return null to signal that no further
    split is necessary. Conversely, if you need to perform a split, you set the candidate split position to the
    half of the String chunk remaining to be parsed. But you don’t use this split position directly because
    want to avoid splitting in the middle of a word, so you move forward until you find a blank
    Character . Once you find an opportune split position, you create a new Spliterator that will traverse
    the substring chunk going from the current position to the split one; you set the current position of
    this to the split one, because the part before it will be managed by the new Spliterator , and then you
    return it.

-   The estimatedSize of elements still to be traversed is the difference between the total length of the
    String parsed by this Spliterator and the position currently iterated.

-   Finally, the characteristic method signals to the framework that this Spliterator is ORDERED
    (the order is just the sequence of Character s in the String ), SIZED (the value returned by the
    estimatedSize method is exact), SUBSIZED (the other Spliterator s created by the trySplit
    method also have an exact size), NONNULL (there can be no null Character s in the String ), and
    IMMUTABLE (no further Character s can be added while parsing the String because the String
    itself is an immutable class).

// Summary

-   Internal iteration allows you to process a stream in parallel without the need to explicitly use and
    coordinate different threads in your code.

-   Even if processing a stream in parallel is so easy, there’s no guarantee that doing so will make your
    programs run faster under all circumstances. Behavior and performance of parallel software can
    sometimes be counterintuitive, and for this reason it’s always necessary to measure them and be sure
    that you’re not actually slowing your programs down.

-   Parallel execution of an operation on a set of data, as done by a parallel stream, can provide a
    performance boost, especially when the number of elements to be processed is huge or the processing
    of each single element is particularly time consuming.

-   From a performance point of view, using the right data structure, for instance, employing primitive
    streams instead of nonspecialized ones whenever possible, is almost always more important than
    trying to parallelize some operations.

-   The fork/join framework lets you recursively split a parallelizable task into smaller tasks, execute
    them on different threads, and then combine the results of each subtask in order to produce the
    overall result.

-   Spliterator s define how a parallel stream can split the data it traverses.